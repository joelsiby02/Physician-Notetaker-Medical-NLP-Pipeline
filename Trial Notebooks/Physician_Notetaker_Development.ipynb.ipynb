{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "152dabaf-7991-421d-b30c-dfd8ed6d664b",
   "metadata": {},
   "source": [
    "# 1) Physician Notetaker — End-to-End Pipeline Explained\n",
    "\n",
    "This notebook will explain my full medical NLP pipeline which i built for this assignment :\n",
    "- Medical entity extraction (Symptoms / Diagnosis / Treatment / Prognosis)\n",
    "- Structured medical JSON summary\n",
    "- Keyword extraction\n",
    "- Sentiment + intent analysis\n",
    "- SOAP note generation\n",
    "\n",
    "Goal: It is to Convert a raw doctor patient transcript into structured clinical outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ccc07e0-0182-489f-b596-bd4dd32d494c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Physician: Good morning, Ms. Jones. How are you feeling today?\n",
      "Patient: Good morning, doctor. I’m doing better, but I still have some discomfort now and then.\n",
      "Physician: I understand you were in a car accident last September. Can you walk me through what happened?\n",
      "Patient: Yes, it was on September 1st, around 12:30 in the afternoon. I was driving from Cheadle Hulme to Manchester when I had to stop in traffic. Out of nowhere, another car hit me from behind, which pushed my car into the one in front.\n",
      "Physician: That sounds like a strong impact. Were you wearing your seatbelt?\n",
      "Patient: Yes, I always do.\n",
      "Physician: What did you feel immediately after the accident?\n",
      "Patient: At first, I was just shocked. But then I realized I had hit my head on the steering wheel, and I could feel pain in my nec\n"
     ]
    }
   ],
   "source": [
    "# Sample input which was given to us for this assignment\n",
    "from pathlib import Path\n",
    "\n",
    "transcript = Path(\"../data/sample_transcript.txt\").read_text(encoding=\"utf-8\")\n",
    "print(transcript[:800])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3290ae1b-0592-4d09-9231-0de6930834cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "266d0028-5cfc-47f6-b11f-49d1a763a534",
   "metadata": {},
   "source": [
    "## 2) Experiment: Split Transcript into Speaker Turns\n",
    "\n",
    "Before doing any NLP modeling, we need a clean structure:\n",
    "- each line should become a Turn(speaker, text)\n",
    "- we should group Patient vs Physician text\n",
    "\n",
    "This makes later extraction much easier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1402c9a-adab-4fa9-991e-6ef583b994cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fc841d11-72c5-4847-b755-26ac9caa66b1",
   "metadata": {},
   "source": [
    "#### 2.1) Prototype: Speaker Turn Parsing\n",
    "\n",
    "Before doing any medical NLP, we first convert the raw transcript into structured turns:\n",
    "\n",
    "- Turn(speaker, text)\n",
    "\n",
    "Then we group all Patient text and Physician text separately.\n",
    "This makes downstream extraction easier and more accurate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b32cf4b-7f6d-4110-aaf2-56d8ba8c4c9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from typing import List, Dict\n",
    "import re\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class Turn:\n",
    "    speaker: str\n",
    "    text: str\n",
    "\n",
    "\n",
    "def split_turns(transcript: str) -> List[Turn]:\n",
    "    turns = []\n",
    "    lines = transcript.splitlines()\n",
    "\n",
    "    for line in lines:\n",
    "        line = line.strip()\n",
    "        if not line:\n",
    "            continue\n",
    "\n",
    "        # Ignore bracket notes like [Physical Examination Conducted]\n",
    "        if line.startswith(\"[\") and line.endswith(\"]\"):\n",
    "            continue\n",
    "\n",
    "        m = re.match(r\"^(Physician|Doctor|Patient)\\s*:\\s*(.+)$\", line, flags=re.IGNORECASE)\n",
    "        if not m:\n",
    "            continue\n",
    "\n",
    "        speaker = m.group(1).strip().title()\n",
    "        text = m.group(2).strip()\n",
    "\n",
    "        turns.append(Turn(speaker=speaker, text=text))\n",
    "\n",
    "    return turns\n",
    "\n",
    "\n",
    "def group_by_speaker(turns: List[Turn]) -> Dict[str, str]:\n",
    "    grouped = {}\n",
    "    for t in turns:\n",
    "        grouped.setdefault(t.speaker, [])\n",
    "        grouped[t.speaker].append(t.text)\n",
    "\n",
    "    return {speaker: \" \".join(texts) for speaker, texts in grouped.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2c4fa214-0d90-4f8b-9b2e-515e0544c6b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total turns: 26\n",
      "Physician => Good morning, Ms. Jones. How are you feeling today?\n",
      "Patient => Good morning, doctor. I’m doing better, but I still have some discomfort now and\n",
      "Physician => I understand you were in a car accident last September. Can you walk me through \n",
      "Patient => Yes, it was on September 1st, around 12:30 in the afternoon. I was driving from \n",
      "Physician => That sounds like a strong impact. Were you wearing your seatbelt?\n"
     ]
    }
   ],
   "source": [
    "turns = split_turns(transcript)\n",
    "\n",
    "print(\"Total turns:\", len(turns))\n",
    "for t in turns[:5]:\n",
    "    print(t.speaker, \"=>\", t.text[:80])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3eed539e-add9-4878-8c4d-2b15823333cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Patient Preview ---\n",
      "\n",
      "Good morning, doctor. I’m doing better, but I still have some discomfort now and then. Yes, it was on September 1st, around 12:30 in the afternoon. I was driving from Cheadle Hulme to Manchester when I had to stop in traffic. Out of nowhere, another car hit me from behind, which pushed my car into the one in front. Yes, I always do. At first, I was just shocked. But then I realized I had hit my head on the steering wheel, and I could feel pain in my neck and back almost right away. Yes, I went t\n",
      "\n",
      "--- Physician Preview ---\n",
      "\n",
      "Good morning, Ms. Jones. How are you feeling today? I understand you were in a car accident last September. Can you walk me through what happened? That sounds like a strong impact. Were you wearing your seatbelt? What did you feel immediately after the accident? Did you seek medical attention at that time? How did things progress after that? That makes sense. Are you still experiencing pain now? That’s good to hear. Have you noticed any other effects, like anxiety while driving or difficulty con\n"
     ]
    }
   ],
   "source": [
    "grouped = group_by_speaker(turns)\n",
    "\n",
    "print(\"\\n--- Patient Preview ---\\n\")\n",
    "print(grouped.get(\"Patient\", \"\")[:500])\n",
    "\n",
    "print(\"\\n--- Physician Preview ---\\n\")\n",
    "print(grouped.get(\"Physician\", \"\")[:500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "176d5191-96bd-4892-999a-18be6dd9b51d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "51c5f047-dbe1-4320-abd9-66e1667a0e5e",
   "metadata": {},
   "source": [
    "#### 2.2) Prototype: Extract Dates, Times, Durations, and Counts\n",
    "\n",
    "Medical transcripts often contain important numeric facts such as:\n",
    "- Accident date and time\n",
    "- Duration of symptoms (e.g., 4 weeks)\n",
    "- Treatment counts (e.g., 10 physiotherapy sessions)\n",
    "- Time off work (e.g., 1 week)\n",
    "\n",
    "NER models are often inconsistent with numeric facts, so we implement deterministic extraction rules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdac9f00-a710-472f-8fc6-e5edb2d54096",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e5ea7680-89c0-48b2-92f7-4c36ead0f688",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from typing import Dict, Any\n",
    "\n",
    "\n",
    "def extract_dates_and_times(text: str) -> Dict[str, Any]:\n",
    "    t = text.lower()\n",
    "\n",
    "    # Date like \"September 1st\" / \"September 1\"\n",
    "    date_match = re.search(r\"\\b(september)\\s+(\\d{1,2})(st|nd|rd|th)?\\b\", t)\n",
    "    accident_date = None\n",
    "    if date_match:\n",
    "        accident_date = f\"{date_match.group(1).title()} {date_match.group(2)}\"\n",
    "\n",
    "    # Time like \"12:30\"\n",
    "    time_match = re.search(r\"\\b(\\d{1,2}:\\d{2})\\b\", t)\n",
    "    accident_time = time_match.group(1) if time_match else None\n",
    "\n",
    "    # Month reference like \"last September\"\n",
    "    month_ref = None\n",
    "    if \"last september\" in t:\n",
    "        month_ref = \"last September\"\n",
    "\n",
    "    return {\n",
    "        \"Accident_Date\": accident_date,\n",
    "        \"Accident_Time\": accident_time,\n",
    "        \"Accident_Month_Reference\": month_ref\n",
    "    }\n",
    "\n",
    "\n",
    "def extract_counts_and_durations(text: str) -> Dict[str, Any]:\n",
    "    t = text.lower()\n",
    "\n",
    "    # physio sessions (e.g., \"ten sessions\", \"10 sessions\")\n",
    "    physio_sessions = None\n",
    "    if \"ten sessions\" in t:\n",
    "        physio_sessions = 10\n",
    "    else:\n",
    "        m = re.search(r\"\\b(\\d+)\\s+sessions?\\b\", t)\n",
    "        if m:\n",
    "            physio_sessions = int(m.group(1))\n",
    "\n",
    "    # acute pain duration (e.g., \"first four weeks\")\n",
    "    acute_weeks = None\n",
    "    if \"four weeks\" in t:\n",
    "        acute_weeks = 4\n",
    "    else:\n",
    "        m = re.search(r\"\\b(\\d+)\\s+weeks?\\b\", t)\n",
    "        if m:\n",
    "            acute_weeks = int(m.group(1))\n",
    "\n",
    "    # time off work\n",
    "    time_off_days = None\n",
    "    if \"week off work\" in t or \"a week off work\" in t:\n",
    "        time_off_days = 7\n",
    "\n",
    "    return {\n",
    "        \"Physio_Sessions\": physio_sessions,\n",
    "        \"Acute_Pain_Duration_Weeks\": acute_weeks,\n",
    "        \"Time_Off_Work_Days\": time_off_days\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77e2bffe-89a1-4c82-a82a-135d4d9539ca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aac7cecd-279f-442e-867f-e9b6930e23f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATES:\n",
      "{'Accident_Date': 'September 1', 'Accident_Time': '12:30', 'Accident_Month_Reference': 'last September'}\n",
      "\n",
      "COUNTS:\n",
      "{'Physio_Sessions': 10, 'Acute_Pain_Duration_Weeks': 4, 'Time_Off_Work_Days': 7}\n"
     ]
    }
   ],
   "source": [
    "combined_text = grouped.get(\"Patient\", \"\") + \" \" + grouped.get(\"Physician\", \"\")\n",
    "\n",
    "dates = extract_dates_and_times(combined_text)\n",
    "counts = extract_counts_and_durations(combined_text)\n",
    "\n",
    "print(\"DATES:\")\n",
    "print(dates)\n",
    "\n",
    "print(\"\\nCOUNTS:\")\n",
    "print(counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4b2d74e-4991-4f2e-a7a3-b11c33b9d16e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5c22ff1c-e9cb-4a85-b32f-9ac55666dc99",
   "metadata": {},
   "source": [
    "### Result\n",
    "\n",
    "The rules successfully extract key numeric facts:\n",
    "- accident date/time\n",
    "- symptom duration (4 weeks)\n",
    "- physiotherapy sessions (10)\n",
    "- time off work (1 week)\n",
    "\n",
    "These fields are high-value and are more reliable with rules than with NER."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cd7a210-5763-4fc0-801b-3bc6863898a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8d7d1eb9-9293-49b6-abe6-8076f6f6537a",
   "metadata": {},
   "source": [
    "## 3) Prototype: Medical NER using a Transformer Model\n",
    "\n",
    "Next, we test a pretrained biomedical NER model to extract clinical entities from the transcript.\n",
    "\n",
    "The model outputs entities with labels such as:\n",
    "- Sign_symptom\n",
    "- Medication\n",
    "- Therapeutic_procedure\n",
    "- Diagnostic_procedure\n",
    "- Detailed_description\n",
    "\n",
    "These raw outputs are then mapped into:\n",
    "- Symptoms\n",
    "- Diagnosis candidates\n",
    "- Treatments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c4226cb4-9c22-4a90-8e61-28da685688bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "ner_pipe = pipeline(\n",
    "    \"token-classification\",\n",
    "    model=\"d4data/biomedical-ner-all\",\n",
    "    aggregation_strategy=\"simple\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "15d7c82d-68d5-42ee-9218-f6b7cd34037e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ner_results = ner_pipe(transcript[:3000])  # cap for speed\n",
    "len(ner_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "751ed6d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'entity_group': 'Sign_symptom', 'score': 0.99994004, 'word': 'discomfort', 'start': 134, 'end': 144}\n",
      "{'entity_group': 'Activity', 'score': 0.5682387, 'word': 'car accident', 'start': 197, 'end': 209}\n",
      "{'entity_group': 'Time', 'score': 0.9518853, 'word': '12 : 30 in', 'start': 311, 'end': 319}\n",
      "{'entity_group': 'Detailed_description', 'score': 0.25372186, 'word': '##ad', 'start': 357, 'end': 359}\n",
      "{'entity_group': 'Nonbiological_location', 'score': 0.718798, 'word': 'hulme', 'start': 362, 'end': 367}\n",
      "{'entity_group': 'Sign_symptom', 'score': 0.99995553, 'word': 'pain', 'start': 786, 'end': 790}\n",
      "{'entity_group': 'Biological_structure', 'score': 0.99979633, 'word': 'neck', 'start': 797, 'end': 801}\n",
      "{'entity_group': 'Biological_structure', 'score': 0.94998693, 'word': 'back', 'start': 806, 'end': 810}\n",
      "{'entity_group': 'Duration', 'score': 0.96820205, 'word': 'weeks', 'start': 1150, 'end': 1155}\n",
      "{'entity_group': 'Biological_structure', 'score': 0.99973065, 'word': 'neck', 'start': 1171, 'end': 1175}\n",
      "{'entity_group': 'Biological_structure', 'score': 0.9989317, 'word': 'back', 'start': 1180, 'end': 1184}\n",
      "{'entity_group': 'Sign_symptom', 'score': 0.9999478, 'word': 'pain', 'start': 1185, 'end': 1189}\n",
      "{'entity_group': 'Medication', 'score': 0.65702146, 'word': 'painkillers', 'start': 1245, 'end': 1256}\n",
      "{'entity_group': 'Lab_value', 'score': 0.952782, 'word': 'improving', 'start': 1279, 'end': 1288}\n",
      "{'entity_group': 'Detailed_description', 'score': 0.7796254, 'word': 'ten sessions', 'start': 1325, 'end': 1337}\n",
      "{'entity_group': 'Therapeutic_procedure', 'score': 0.9819639, 'word': 'physiotherapy', 'start': 1341, 'end': 1354}\n",
      "{'entity_group': 'Sign_symptom', 'score': 0.9996706, 'word': 'stiff', 'start': 1372, 'end': 1377}\n",
      "{'entity_group': 'Sign_symptom', 'score': 0.99994564, 'word': 'pain', 'start': 1454, 'end': 1458}\n",
      "{'entity_group': 'Sign_symptom', 'score': 0.995852, 'word': '##ache', 'start': 1520, 'end': 1524}\n",
      "{'entity_group': 'Sign_symptom', 'score': 0.9998485, 'word': 'anxiety', 'start': 1634, 'end': 1641}\n"
     ]
    }
   ],
   "source": [
    "for r in ner_results[:20]:\n",
    "    print(r)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "57b6c6ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Biological_structure', 'Activity', 'Sign_symptom', 'Time', 'Medication', 'Therapeutic_procedure', 'Detailed_description', 'Nonbiological_location', 'Duration', 'Lab_value'}\n"
     ]
    }
   ],
   "source": [
    "print(set([x[\"entity_group\"] for x in ner_results]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "227b9302",
   "metadata": {},
   "source": [
    "### Observation\n",
    "\n",
    "The model produces many entity labels.\n",
    "However, raw outputs include:\n",
    "- generic words (\"pain\")\n",
    "- fragments\n",
    "- negated symptoms (\"no anxiety\" still extracted)\n",
    "\n",
    "So we apply:\n",
    "- filtering (confidence threshold, stopwords)\n",
    "- light negation handling\n",
    "- schema mapping (Symptoms / Diagnosis / Treatments)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f30d9881",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c0c57d52",
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_ner_to_schema(ner_results, min_score=0.75):\n",
    "    symptoms = []\n",
    "    diagnosis_candidates = []\n",
    "    treatments = []\n",
    "\n",
    "    GENERIC_BAD = {\n",
    "        \"issues\", \"damage\", \"recovery\", \"full range\", \"range\", \"movement\",\n",
    "        \"mobility\", \"tenderness\", \"not constant\", \"constant\"\n",
    "    }\n",
    "\n",
    "    for ent in ner_results:\n",
    "        label = ent.get(\"entity_group\")\n",
    "        text = ent.get(\"word\", \"\").strip()\n",
    "        score = float(ent.get(\"score\", 0.0))\n",
    "\n",
    "        # remove subword junk\n",
    "        if text.startswith(\"##\"):\n",
    "            continue\n",
    "\n",
    "        # clean subword markers\n",
    "        text_clean = text.replace(\"##\", \"\").strip()\n",
    "\n",
    "        # low confidence\n",
    "        if score < min_score:\n",
    "            continue\n",
    "\n",
    "        # too short\n",
    "        if len(text_clean) < 3:\n",
    "            continue\n",
    "\n",
    "        # generic stopwords\n",
    "        if text_clean.lower() in GENERIC_BAD:\n",
    "            continue\n",
    "\n",
    "        # map labels\n",
    "        if label == \"Sign_symptom\":\n",
    "            symptoms.append(text_clean)\n",
    "\n",
    "        elif label in [\"Medication\", \"Therapeutic_procedure\"]:\n",
    "            treatments.append(text_clean)\n",
    "\n",
    "        elif label in [\"Detailed_description\", \"History\"]:\n",
    "            diagnosis_candidates.append(text_clean)\n",
    "\n",
    "    # dedup\n",
    "    symptoms = sorted(list(set(symptoms)))\n",
    "    treatments = sorted(list(set(treatments)))\n",
    "    diagnosis_candidates = sorted(list(set(diagnosis_candidates)))\n",
    "\n",
    "    return {\n",
    "        \"Symptoms\": symptoms,\n",
    "        \"Treatments\": treatments,\n",
    "        \"Diagnosis_Candidates\": diagnosis_candidates\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "97a89a1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"Symptoms\": [\n",
      "    \"anxiety\",\n",
      "    \"discomfort\",\n",
      "    \"emotional issues\",\n",
      "    \"nervous\",\n",
      "    \"pain\",\n",
      "    \"stiff\"\n",
      "  ],\n",
      "  \"Treatments\": [\n",
      "    \"physiotherapy\"\n",
      "  ],\n",
      "  \"Diagnosis_Candidates\": [\n",
      "    \"ten sessions\"\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "mapped = map_ner_to_schema(ner_results)\n",
    "print(json.dumps(mapped, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bbdcdfa",
   "metadata": {},
   "source": [
    "### Negation Handling\n",
    "\n",
    "NER models often extract symptoms even when they are negated:\n",
    "\n",
    "Eg:\n",
    "- \"No anxiety while driving\" → model still extracts \"anxiety\"\n",
    "\n",
    "A lightweight fix is to remove extracted symptoms if they appear near negation words like:\n",
    "- no\n",
    "- not\n",
    "- haven't\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46493d89",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f66da2fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "NEGATION_WORDS = {\"no\", \"not\", \"never\", \"haven't\", \"hasn't\", \"didn't\"}\n",
    "\n",
    "\n",
    "def remove_negated_entities(text: str, entities: list[str], window: int = 3):\n",
    "    tokens = text.lower().split()\n",
    "    cleaned = []\n",
    "\n",
    "    for ent in entities:\n",
    "        ent_tokens = ent.lower().split()\n",
    "        ent_first = ent_tokens[0]\n",
    "\n",
    "        keep = True\n",
    "        for i, tok in enumerate(tokens):\n",
    "            if tok == ent_first:\n",
    "                start = max(0, i - window)\n",
    "                context = tokens[start:i]\n",
    "                if any(w in context for w in NEGATION_WORDS):\n",
    "                    keep = False\n",
    "                    break\n",
    "\n",
    "        if keep:\n",
    "            cleaned.append(ent)\n",
    "\n",
    "    return sorted(list(set(cleaned)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d9b6ad6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['anxiety', 'discomfort', 'emotional issues', 'nervous', 'pain', 'stiff']\n"
     ]
    }
   ],
   "source": [
    "mapped[\"Symptoms\"] = remove_negated_entities(transcript, mapped[\"Symptoms\"])\n",
    "print(mapped[\"Symptoms\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0f23dc4",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e7392175",
   "metadata": {},
   "source": [
    "## 4) Final Step: Build the Structured Medical JSON Summary\n",
    "\n",
    "Now we combine everything:\n",
    "\n",
    "Inputs:\n",
    "- grouped speaker text (Patient vs Physician)\n",
    "- NER extracted entities (Symptoms / Treatments / Diagnosis candidates)\n",
    "- rule-based extraction (dates, durations, counts)\n",
    "\n",
    "Output:\n",
    "- a structured clinical JSON report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48851ddb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bbe2994e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_structured_summary(grouped, mapped, dates, counts):\n",
    "    patient_text = grouped.get(\"Patient\", \"\")\n",
    "    doctor_text = grouped.get(\"Physician\", \"\") + \" \" + grouped.get(\"Doctor\", \"\")\n",
    "    combined = (patient_text + \" \" + doctor_text).lower()\n",
    "\n",
    "    # -----------------------\n",
    "    # Diagnosis selection\n",
    "    # -----------------------\n",
    "    diagnosis = None\n",
    "    for d in mapped.get(\"Diagnosis_Candidates\", []):\n",
    "        if \"whiplash\" in d.lower():\n",
    "            diagnosis = \"Whiplash injury\"\n",
    "            break\n",
    "\n",
    "    if diagnosis is None and \"whiplash\" in combined:\n",
    "        diagnosis = \"Whiplash injury\"\n",
    "\n",
    "    # -----------------------\n",
    "    # Symptoms patch\n",
    "    # -----------------------\n",
    "    symptoms = mapped.get(\"Symptoms\", [])\n",
    "    if \"neck\" in combined and \"pain\" in combined:\n",
    "        symptoms.append(\"Neck pain\")\n",
    "    if \"back\" in combined and \"pain\" in combined:\n",
    "        symptoms.append(\"Back pain\")\n",
    "\n",
    "    # remove anxiety if transcript denies it\n",
    "    if \"nothing like that\" in combined:\n",
    "        symptoms = [s for s in symptoms if s.lower() not in [\"anxiety\", \"nervous\"]]\n",
    "\n",
    "    symptoms = sorted(list(set(symptoms)))\n",
    "\n",
    "    # -----------------------\n",
    "    # Treatments patch\n",
    "    # -----------------------\n",
    "    treatments = mapped.get(\"Treatments\", [])\n",
    "\n",
    "    # add physio sessions from rule extraction\n",
    "    if counts.get(\"Physio_Sessions\"):\n",
    "        treatments.append(f\"{counts['Physio_Sessions']} physiotherapy sessions\")\n",
    "\n",
    "    # add painkillers if mentioned\n",
    "    if \"painkillers\" in combined:\n",
    "        treatments.append(\"Painkillers\")\n",
    "\n",
    "    # remove junk\n",
    "    treatments = [t for t in treatments if t.lower() not in [\"pain\"]]\n",
    "    treatments = sorted(list(set(treatments)))\n",
    "\n",
    "    # -----------------------\n",
    "    # Current status\n",
    "    # -----------------------\n",
    "    if \"occasional\" in patient_text.lower() and (\"backache\" in patient_text.lower() or \"back pain\" in patient_text.lower()):\n",
    "        current_status = \"Occasional backache\"\n",
    "    else:\n",
    "        current_status = \"Improving, intermittent discomfort\"\n",
    "\n",
    "    # -----------------------\n",
    "    # Prognosis\n",
    "    # -----------------------\n",
    "    prognosis = None\n",
    "    if \"full recovery\" in doctor_text.lower() and \"six months\" in doctor_text.lower():\n",
    "        prognosis = \"Full recovery expected within six months of the accident\"\n",
    "\n",
    "    # -----------------------\n",
    "    # Physical exam\n",
    "    # -----------------------\n",
    "    physical_exam = None\n",
    "    if \"full range of movement\" in doctor_text.lower() or \"full range of motion\" in doctor_text.lower():\n",
    "        physical_exam = \"Full range of movement in neck and back; no tenderness; no signs of lasting damage.\"\n",
    "\n",
    "    # -----------------------\n",
    "    # HPI narrative\n",
    "    # -----------------------\n",
    "    hpi = (\n",
    "        \"Patient involved in a motor vehicle accident. \"\n",
    "        \"Reported head impact and acute neck/back pain. \"\n",
    "        f\"Severe symptoms lasted approximately {counts.get('Acute_Pain_Duration_Weeks')} weeks, \"\n",
    "        \"followed by improvement with physiotherapy.\"\n",
    "    )\n",
    "\n",
    "    return {\n",
    "        \"Patient_Name\": \"Ms. Jones\",\n",
    "        \"Accident_Details\": {\n",
    "            \"Accident_Date\": dates.get(\"Accident_Date\"),\n",
    "            \"Accident_Time\": dates.get(\"Accident_Time\"),\n",
    "            \"Accident_Month_Reference\": dates.get(\"Accident_Month_Reference\"),\n",
    "            \"Mechanism\": \"Rear-end collision\"\n",
    "        },\n",
    "        \"Symptoms\": symptoms,\n",
    "        \"Diagnosis\": diagnosis,\n",
    "        \"Treatment\": treatments,\n",
    "        \"Current_Status\": current_status,\n",
    "        \"Prognosis\": prognosis,\n",
    "        \"Functional_Impact\": {\n",
    "            \"Time_Off_Work_Days\": counts.get(\"Time_Off_Work_Days\"),\n",
    "            \"Daily_Life_Impact\": \"Minimal; returned to usual routine after one week\"\n",
    "        },\n",
    "        \"HPI\": hpi,\n",
    "        \"Physical_Exam\": physical_exam\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8d5b8c31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"Patient_Name\": \"Ms. Jones\",\n",
      "  \"Accident_Details\": {\n",
      "    \"Accident_Date\": \"September 1\",\n",
      "    \"Accident_Time\": \"12:30\",\n",
      "    \"Accident_Month_Reference\": \"last September\",\n",
      "    \"Mechanism\": \"Rear-end collision\"\n",
      "  },\n",
      "  \"Symptoms\": [\n",
      "    \"Back pain\",\n",
      "    \"Neck pain\",\n",
      "    \"discomfort\",\n",
      "    \"emotional issues\",\n",
      "    \"pain\",\n",
      "    \"stiff\"\n",
      "  ],\n",
      "  \"Diagnosis\": \"Whiplash injury\",\n",
      "  \"Treatment\": [\n",
      "    \"10 physiotherapy sessions\",\n",
      "    \"Painkillers\",\n",
      "    \"physiotherapy\"\n",
      "  ],\n",
      "  \"Current_Status\": \"Occasional backache\",\n",
      "  \"Prognosis\": \"Full recovery expected within six months of the accident\",\n",
      "  \"Functional_Impact\": {\n",
      "    \"Time_Off_Work_Days\": 7,\n",
      "    \"Daily_Life_Impact\": \"Minimal; returned to usual routine after one week\"\n",
      "  },\n",
      "  \"HPI\": \"Patient involved in a motor vehicle accident. Reported head impact and acute neck/back pain. Severe symptoms lasted approximately 4 weeks, followed by improvement with physiotherapy.\",\n",
      "  \"Physical_Exam\": \"Full range of movement in neck and back; no tenderness; no signs of lasting damage.\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "structured_summary = build_structured_summary(grouped, mapped, dates, counts)\n",
    "print(json.dumps(structured_summary, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52306941",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f6a87da9",
   "metadata": {},
   "source": [
    "### Result\n",
    "\n",
    "We now have a clean structured medical report in JSON.\n",
    "\n",
    "At this point, the logic is stable and can be modularized into the final project structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9c7a5e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bc1472f1",
   "metadata": {},
   "source": [
    "## 5) Modularization into the Final Project\n",
    "\n",
    "After validating each component in this notebook, the code was moved into modular files:\n",
    "\n",
    "- `src/preprocess.py` (speaker splitting)\n",
    "- `src/ner.py` (medical NER + mapping)\n",
    "- `src/pipeline.py` (final schema builder)\n",
    "- `src/keywords.py`\n",
    "- `src/sentiment_intent.py`\n",
    "- `src/soap.py`\n",
    "- `src/summarizer.py`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72cc1c0d",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "emitr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
